{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a470d72e",
   "metadata": {},
   "source": [
    "# Projet de Catégorisation de texte (Feature engineering) - Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5727206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U textblob\n",
    "#!pip install -U spacy\n",
    "#!python -m spacy download en\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#ltk.download()\n",
    "#!python -m textblob.download_corpora\n",
    "#!pip install gensim\n",
    "# !pip install mlflow\n",
    "# !pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27db62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import os\n",
    "if os.path.isdir('./bbcsport-fulltext'):\n",
    "    print('repertoire existe')\n",
    "\n",
    "mypath = 'test'\n",
    "\n",
    "from textblob import Word\n",
    "\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import mlflow as mlf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca335917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mornd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mornd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mornd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "mots_stop = stopwords.words('english')\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f4113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = []\n",
    "list_contents = []\n",
    "list_cat = []\n",
    "\n",
    "for path, subdirs, files in os.walk(mypath):\n",
    "    for name in files:\n",
    "        my_path = os.path.join(path, name)\n",
    "        list_files.append(name.split('.')[0])\n",
    "        \n",
    "        with open(my_path, 'r') as file:\n",
    "            content = file.read()\n",
    "            list_contents.append(content)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd56b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'filename':list_files, 'content': list_contents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6cfb68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>003</td>\n",
       "      <td>South Africa far too strong again\\n\\nSecond on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename                                            content\n",
       "0      003  South Africa far too strong again\\n\\nSecond on..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2cc2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df[\"content\"].map(lambda x: TextBlob(x).words)\n",
    "df[\"content\"] = df[\"content\"].map(lambda line :  [mot.lower() for mot in line if mot.lower() not in mots_stop] )\n",
    "df[\"content\"] = df[\"content\"].map(lambda line :  [mot for mot in line if re.match(r'^-?\\d+(?:\\.\\d+)$', mot) is None] )\n",
    "df[\"content\"] = df[\"content\"].map(lambda line :  [mot for mot in line if re.match(r\"^\\'\\w{2}$\", mot) is None] )\n",
    "df[\"content\"] = df[\"content\"].map(lambda line :  [mot for mot in line if re.match(r\"^\\'\\w$\", mot) is None] )\n",
    "df[\"content\"] = df[\"content\"].map(lambda line :  [mot for mot in line if re.match(r\"[^@]+@[^@]+\\.[^@]+\", mot) is None] )\n",
    "df[\"content\"] = df[\"content\"].map(lambda line :  [mot for mot in line if re.match(r\".*\\d+.*\", mot) is None] )\n",
    "df[\"content\"] = df[\"content\"].map(lambda line :  [ps.stem(mot) for mot in line] )\n",
    "df[\"content\"] = df[\"content\"].map(lambda line :  [Word(mot).lemmatize() for mot in line] )\n",
    "df[\"content\"] = df[\"content\"].map(lambda line : \" \".join([mot for mot in line]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76d2cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('filename',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30bc4bc",
   "metadata": {},
   "source": [
    "## Test de Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a29877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loding Trained Model .... \n"
     ]
    }
   ],
   "source": [
    "#Importation du modèle\n",
    "if os.path.exists('models/model.pkl'):\n",
    "    print(\"Loding Trained Model .... \")\n",
    "    model = pickle.load(open('models/model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8d25304",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([df['content'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f806eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier fourni appartient à la catégorie :  cricket\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(predictions)):\n",
    "    print(\"Le fichier fourni appartient à la catégorie : \",predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6c148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
